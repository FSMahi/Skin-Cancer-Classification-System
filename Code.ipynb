{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe01a798",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-27T17:25:16.332610Z",
     "iopub.status.busy": "2025-01-27T17:25:16.332311Z",
     "iopub.status.idle": "2025-01-27T18:00:39.012976Z",
     "shell.execute_reply": "2025-01-27T18:00:39.012038Z"
    },
    "papermill": {
     "duration": 2122.685672,
     "end_time": "2025-01-27T18:00:39.014379",
     "exception": false,
     "start_time": "2025-01-27T17:25:16.328707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 348ms/step - accuracy: 0.6548 - loss: 1.2946 - val_accuracy: 0.6840 - val_loss: 1.0714\n",
      "Epoch 2/50\n",
      "\u001b[1m  1/250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 107ms/step - accuracy: 0.6250 - loss: 1.1390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.1390 - val_accuracy: 0.6840 - val_loss: 1.0742\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 290ms/step - accuracy: 0.6705 - loss: 1.0604 - val_accuracy: 0.6840 - val_loss: 1.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.7592 - val_accuracy: 0.6840 - val_loss: 0.9979\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 287ms/step - accuracy: 0.6600 - loss: 1.0384 - val_accuracy: 0.6845 - val_loss: 0.9831\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 1.2846 - val_accuracy: 0.6840 - val_loss: 0.9921\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 291ms/step - accuracy: 0.6641 - loss: 0.9950 - val_accuracy: 0.6835 - val_loss: 0.9265\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.9771 - val_accuracy: 0.6835 - val_loss: 0.9284\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 291ms/step - accuracy: 0.6733 - loss: 0.9362 - val_accuracy: 0.6890 - val_loss: 0.8673\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8666 - val_accuracy: 0.6890 - val_loss: 0.8700\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 294ms/step - accuracy: 0.6668 - loss: 0.8948 - val_accuracy: 0.6905 - val_loss: 0.8359\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5952 - val_accuracy: 0.6900 - val_loss: 0.8355\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 295ms/step - accuracy: 0.6652 - loss: 0.8837 - val_accuracy: 0.6935 - val_loss: 0.8084\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.6454 - val_accuracy: 0.6930 - val_loss: 0.8144\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 298ms/step - accuracy: 0.6780 - loss: 0.8417 - val_accuracy: 0.7034 - val_loss: 0.7915\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.8396 - val_accuracy: 0.7039 - val_loss: 0.7915\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 290ms/step - accuracy: 0.6848 - loss: 0.8361 - val_accuracy: 0.6990 - val_loss: 0.8042\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.8539 - val_accuracy: 0.6995 - val_loss: 0.7972\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 291ms/step - accuracy: 0.6945 - loss: 0.8160 - val_accuracy: 0.7044 - val_loss: 0.7825\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8607 - val_accuracy: 0.7034 - val_loss: 0.7837\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 292ms/step - accuracy: 0.6952 - loss: 0.8005 - val_accuracy: 0.7004 - val_loss: 0.8198\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.9093 - val_accuracy: 0.7009 - val_loss: 0.8143\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 296ms/step - accuracy: 0.6991 - loss: 0.8049 - val_accuracy: 0.7074 - val_loss: 0.7825\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.0324 - val_accuracy: 0.7054 - val_loss: 0.7820\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 292ms/step - accuracy: 0.6929 - loss: 0.8059 - val_accuracy: 0.7079 - val_loss: 0.7618\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 0.9500 - val_accuracy: 0.7089 - val_loss: 0.7600\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 294ms/step - accuracy: 0.6920 - loss: 0.8179 - val_accuracy: 0.7194 - val_loss: 0.7801\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 1.0155 - val_accuracy: 0.7164 - val_loss: 0.7783\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 290ms/step - accuracy: 0.6924 - loss: 0.8051 - val_accuracy: 0.7119 - val_loss: 0.7638\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.6979 - val_accuracy: 0.7124 - val_loss: 0.7622\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 292ms/step - accuracy: 0.6971 - loss: 0.7982 - val_accuracy: 0.7264 - val_loss: 0.7593\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.5227 - val_accuracy: 0.7244 - val_loss: 0.7636\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 292ms/step - accuracy: 0.7022 - loss: 0.7798 - val_accuracy: 0.7174 - val_loss: 0.7726\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.7796 - val_accuracy: 0.7174 - val_loss: 0.7713\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 294ms/step - accuracy: 0.7051 - loss: 0.7793 - val_accuracy: 0.7109 - val_loss: 0.7646\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.7432 - val_accuracy: 0.7124 - val_loss: 0.7589\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 292ms/step - accuracy: 0.7020 - loss: 0.7682 - val_accuracy: 0.7159 - val_loss: 0.7716\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.6530 - val_accuracy: 0.7129 - val_loss: 0.7827\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 293ms/step - accuracy: 0.7005 - loss: 0.7738 - val_accuracy: 0.7224 - val_loss: 0.7403\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.8425 - val_accuracy: 0.7214 - val_loss: 0.7384\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 293ms/step - accuracy: 0.7097 - loss: 0.7680 - val_accuracy: 0.7144 - val_loss: 0.7502\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.2425 - val_accuracy: 0.7119 - val_loss: 0.7578\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 295ms/step - accuracy: 0.7029 - loss: 0.7669 - val_accuracy: 0.7169 - val_loss: 0.7493\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6206 - val_accuracy: 0.7169 - val_loss: 0.7515\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 292ms/step - accuracy: 0.7019 - loss: 0.7749 - val_accuracy: 0.7219 - val_loss: 0.7407\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.8648 - val_accuracy: 0.7224 - val_loss: 0.7404\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 293ms/step - accuracy: 0.7069 - loss: 0.7630 - val_accuracy: 0.7264 - val_loss: 0.7621\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.6991 - val_accuracy: 0.7259 - val_loss: 0.7508\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 292ms/step - accuracy: 0.7063 - loss: 0.7659 - val_accuracy: 0.7189 - val_loss: 0.7451\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.7518 - val_accuracy: 0.7169 - val_loss: 0.7530\n",
      "Model training completed and saved as capsule_model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Capsule Layer\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsules, dim_capsule, routings=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='capsule_kernel',\n",
    "                                      shape=(input_shape[-1], self.num_capsules * self.dim_capsule),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        u_hat = tf.linalg.matmul(inputs, self.kernel)\n",
    "        u_hat = tf.reshape(u_hat, (-1, inputs.shape[1], self.num_capsules, self.dim_capsule))\n",
    "        u_hat = tf.transpose(u_hat, perm=[0, 2, 1, 3])\n",
    "        for i in range(self.routings):\n",
    "            c = tf.nn.softmax(tf.reduce_sum(u_hat, axis=-1, keepdims=True), axis=2)\n",
    "            outputs = tf.linalg.matmul(c, u_hat, transpose_a=True)\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(outputs), axis=-1))\n",
    "\n",
    "# Length Layer (for output probabilities)\n",
    "class Length(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "\n",
    "# Capsule Network Model\n",
    "def create_capsule_model(input_shape, n_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Conv Layer\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Capsule Layer\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Reshape((-1, 128))(x)\n",
    "    capsules = CapsuleLayer(num_capsules=n_classes, dim_capsule=16, routings=3)(x)\n",
    "\n",
    "    # Output Layer\n",
    "    output = Length()(capsules)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Kaggle-specific setup\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to HAM10000 dataset files\n",
    "    metadata_path = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\n",
    "    images_dir1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/\"\n",
    "    images_dir2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2/\"\n",
    "\n",
    "    # Load metadata\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "    # Combine image paths\n",
    "    metadata['image_path'] = metadata['image_id'].apply(\n",
    "        lambda x: images_dir1 + x + \".jpg\" if os.path.exists(images_dir1 + x + \".jpg\") else images_dir2 + x + \".jpg\"\n",
    "    )\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    metadata['label'] = le.fit_transform(metadata['dx'])\n",
    "\n",
    "    # Load images and preprocess\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in metadata.iterrows():\n",
    "        img = load_img(row['image_path'], target_size=(224, 224))  # Resize to match model input\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "        images.append(img_array)\n",
    "        labels.append(row['label'])\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    images = np.array(images)\n",
    "    labels = to_categorical(labels, num_classes=7)  # One-hot encode labels\n",
    "\n",
    "    # Data Augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Shuffle and split the data\n",
    "    images, labels = shuffle(images, labels, random_state=42)\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    input_shape = (224, 224, 3)  # Adjust for HAM10000 image sizes\n",
    "    n_classes = 7  # Number of skin cancer types\n",
    "    model = create_capsule_model(input_shape, n_classes)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        datagen.flow(train_data, train_labels, batch_size=32),\n",
    "        validation_data=(val_data, val_labels),\n",
    "        epochs=50,  # Increased epochs for better performance\n",
    "        steps_per_epoch=len(train_data) // 32\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save(\"capsule_model.h5\")\n",
    "\n",
    "    print(\"Model training completed and saved as capsule_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e210300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T18:00:39.614165Z",
     "iopub.status.busy": "2025-01-27T18:00:39.613861Z",
     "iopub.status.idle": "2025-01-27T18:00:50.916104Z",
     "shell.execute_reply": "2025-01-27T18:00:50.915219Z"
    },
    "papermill": {
     "duration": 11.602926,
     "end_time": "2025-01-27T18:00:50.917600",
     "exception": false,
     "start_time": "2025-01-27T18:00:39.314674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\r\n",
      "  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\r\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\r\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\r\n",
      "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\r\n",
      "Collecting ffmpy (from gradio)\r\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting gradio-client==1.6.0 (from gradio)\r\n",
      "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\r\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\r\n",
      "Collecting markupsafe~=2.0 (from gradio)\r\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\r\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\r\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\r\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\r\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\r\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\r\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\r\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\r\n",
      "Collecting ruff>=0.2.2 (from gradio)\r\n",
      "  Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\r\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\r\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting semantic-version~=2.0 (from gradio)\r\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\r\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\r\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\r\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\r\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\r\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.6.0->gradio) (2024.9.0)\r\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.6.0->gradio) (14.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\r\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\r\n",
      "Downloading gradio-5.13.1-py3-none-any.whl (57.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastapi-0.115.7-py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\r\n",
      "Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\r\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\r\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\r\n",
      "Installing collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\r\n",
      "  Attempting uninstall: markupsafe\r\n",
      "    Found existing installation: MarkupSafe 3.0.2\r\n",
      "    Uninstalling MarkupSafe-3.0.2:\r\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\r\n",
      "Successfully installed fastapi-0.115.7 ffmpy-0.5.0 gradio-5.13.1 gradio-client-1.6.0 markupsafe-2.1.5 python-multipart-0.0.20 ruff-0.9.3 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f8ca09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T18:00:51.569562Z",
     "iopub.status.busy": "2025-01-27T18:00:51.569262Z",
     "iopub.status.idle": "2025-01-27T18:00:56.494194Z",
     "shell.execute_reply": "2025-01-27T18:00:56.493483Z"
    },
    "papermill": {
     "duration": 5.275785,
     "end_time": "2025-01-27T18:00:56.495389",
     "exception": false,
     "start_time": "2025-01-27T18:00:51.219604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model: Error when deserializing class 'CapsuleLayer' using config={'name': 'capsule_layer', 'num_capsules': 7, 'dim_capsule': 16, 'routings': 3, 'trainable': True, 'dtype': 'float32'}.\n",
      "\n",
      "Exception encountered: Unrecognized keyword arguments passed to CapsuleLayer: {'dim_capsule': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://240eb555f02edccb38.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://240eb555f02edccb38.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Define CapsuleLayer class with a default value for dim_capsules\n",
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, num_capsules, dim_capsules=16, routings=3, **kwargs):\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsules = dim_capsules  # Default value for dim_capsules\n",
    "        self.routings = routings\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Weight initialization\n",
    "        self.W = self.add_weight(name=\"capsule_weight\",\n",
    "                                 shape=(input_shape[1], self.num_capsules, self.dim_capsules),\n",
    "                                 initializer=\"glorot_uniform\",\n",
    "                                 trainable=True)\n",
    "        super(CapsuleLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Capsule forward pass (simplified)\n",
    "        u_hat = K.batch_dot(inputs, self.W, [2, 1])  # Apply the transformation matrix\n",
    "        return u_hat\n",
    "\n",
    "# Load the Capsule Network model\n",
    "try:\n",
    "    model = load_model(\"capsule_model.h5\", custom_objects={\"CapsuleLayer\": CapsuleLayer}, compile=False)\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "# Define class labels\n",
    "class_labels = [\n",
    "    'Melanocytic nevi',\n",
    "    'Melanoma',\n",
    "    'Benign keratosis-like lesions',\n",
    "    'Basal cell carcinoma',\n",
    "    'Actinic keratoses',\n",
    "    'Vascular lesions',\n",
    "    'Dermatofibroma'\n",
    "]\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((224, 224))  # Resize to the correct model's expected input size\n",
    "    image = np.array(image)  # Convert image to numpy array\n",
    "    image = image.astype('float32')  # Convert to float32\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    image = image / 255.0  # Normalize the image\n",
    "    return image\n",
    "\n",
    "# Prediction function\n",
    "def predict_skin_cancer(image):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image)\n",
    "\n",
    "    # Predict the class probabilities\n",
    "    predictions = model.predict(image)\n",
    "\n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Get the corresponding label\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "    # Get the confidence score (probability of the predicted class)\n",
    "    confidence_score = np.max(predictions) * 100\n",
    "\n",
    "    return predicted_label, confidence_score\n",
    "\n",
    "# Custom CSS for title box with frame and larger text size (no purple theme)\n",
    "css = \"\"\"\n",
    "h1 {\n",
    "    font-size: 40px;\n",
    "    text-align: center;\n",
    "    padding: 20px;\n",
    "    background-color: #e55b13;\n",
    "    color: white;\n",
    "    border: 2px solid #333;\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    "body {\n",
    "    background-color: #f0f0f0;\n",
    "    color: black;\n",
    "    font-family: Arial, sans-serif;\n",
    "}\n",
    "\n",
    ".gradio-container {\n",
    "    border-radius: 10px;\n",
    "    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "    padding: 20px;\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_skin_cancer,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload a Dermoscopic Image\", interactive=True),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Predicted Skin Cancer Type\"),\n",
    "        gr.Textbox(label=\"Confidence Score (%)\")\n",
    "    ],\n",
    "    title=\"Skin Cancer Detection System\",\n",
    "    description=\"This system uses a Capsule Network to detect 7 types of skin cancer from dermoscopic images.\",\n",
    "    theme=None,  # No theme applied\n",
    "    allow_flagging=\"never\",  # Optional: hide flagging\n",
    "    css=css  # Apply custom CSS\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36393490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T18:00:57.096404Z",
     "iopub.status.busy": "2025-01-27T18:00:57.096100Z",
     "iopub.status.idle": "2025-01-27T18:00:57.903904Z",
     "shell.execute_reply": "2025-01-27T18:00:57.902801Z"
    },
    "papermill": {
     "duration": 1.106013,
     "end_time": "2025-01-27T18:00:57.905317",
     "exception": false,
     "start_time": "2025-01-27T18:00:56.799304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model: Error when deserializing class 'CapsuleLayer' using config={'name': 'capsule_layer', 'num_capsules': 7, 'dim_capsule': 16, 'routings': 3, 'trainable': True, 'dtype': 'float32'}.\n",
      "\n",
      "Exception encountered: Unrecognized keyword arguments passed to CapsuleLayer: {'dim_capsule': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://668a6b7a4f4fe02b59.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://668a6b7a4f4fe02b59.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Define CapsuleLayer class with a default value for dim_capsules\n",
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, num_capsules, dim_capsules=16, routings=3, **kwargs):\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsules = dim_capsules  # Default value for dim_capsules\n",
    "        self.routings = routings\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Weight initialization\n",
    "        self.W = self.add_weight(name=\"capsule_weight\",\n",
    "                                 shape=(input_shape[1], self.num_capsules, self.dim_capsules),\n",
    "                                 initializer=\"glorot_uniform\",\n",
    "                                 trainable=True)\n",
    "        super(CapsuleLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Capsule forward pass (simplified)\n",
    "        u_hat = K.batch_dot(inputs, self.W, [2, 1])  # Apply the transformation matrix\n",
    "        return u_hat\n",
    "\n",
    "# Load the Capsule Network model\n",
    "try:\n",
    "    model = load_model(\"capsule_model.h5\", custom_objects={\"CapsuleLayer\": CapsuleLayer}, compile=False)\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "# Define class labels\n",
    "class_labels = [\n",
    "    'Melanocytic nevi',\n",
    "    'Melanoma',\n",
    "    'Benign keratosis-like lesions',\n",
    "    'Basal cell carcinoma',\n",
    "    'Actinic keratoses',\n",
    "    'Vascular lesions',\n",
    "    'Dermatofibroma'\n",
    "]\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((224, 224))  # Resize to the correct model's expected input size\n",
    "    image = np.array(image)  # Convert image to numpy array\n",
    "    image = image.astype('float32')  # Convert to float32\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    image = image / 255.0  # Normalize the image\n",
    "    return image\n",
    "\n",
    "# Prediction function\n",
    "def predict_skin_cancer(image):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image)\n",
    "\n",
    "    # Predict the class probabilities\n",
    "    predictions = model.predict(image)\n",
    "\n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Get the corresponding label\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "    # Get the confidence score (probability of the predicted class)\n",
    "    confidence_score = np.max(predictions) * 100\n",
    "\n",
    "    return predicted_label, confidence_score\n",
    "\n",
    "# Custom CSS for purple theme and title box with frame\n",
    "css = \"\"\"\n",
    "body {\n",
    "    background-color: #7A4E96;\n",
    "    color: white;\n",
    "    font-family: Arial, sans-serif;\n",
    "}\n",
    "\n",
    "h1 {\n",
    "    font-size: 36px;\n",
    "    text-align: center;\n",
    "    padding: 20px;\n",
    "    background-color: #5d3377;\n",
    "    border-radius: 10px;\n",
    "    border: 2px solid #7A4E96;\n",
    "}\n",
    "\n",
    "h3 {\n",
    "    font-size: 28px;\n",
    "}\n",
    "\n",
    ".gradio-container {\n",
    "    border-radius: 10px;\n",
    "    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "    padding: 20px;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "button {\n",
    "    background-color: #7A4E96;\n",
    "    color: white;\n",
    "    font-size: 18px;\n",
    "    border: none;\n",
    "    padding: 10px 20px;\n",
    "    border-radius: 5px;\n",
    "    cursor: pointer;\n",
    "}\n",
    "\n",
    "button:hover {\n",
    "    background-color: #5d3377;\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_skin_cancer,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload a Dermoscopic Image\", interactive=True),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Predicted Skin Cancer Type\"),\n",
    "        gr.Textbox(label=\"Confidence Score (%)\")\n",
    "    ],\n",
    "    title=\"Skin Cancer Detection System\",\n",
    "    description=\"This system uses a Capsule Network to detect 7 types of skin cancer from dermoscopic images.\",\n",
    "    theme=\"default\",  # Use the default theme\n",
    "    allow_flagging=\"never\",  # Optional: hide flagging\n",
    "    css=css  # Apply custom CSS\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d7a0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T18:00:58.554645Z",
     "iopub.status.busy": "2025-01-27T18:00:58.554320Z",
     "iopub.status.idle": "2025-01-27T18:01:02.253210Z",
     "shell.execute_reply": "2025-01-27T18:01:02.252064Z"
    },
    "papermill": {
     "duration": 4.005323,
     "end_time": "2025-01-27T18:01:02.255485",
     "exception": false,
     "start_time": "2025-01-27T18:00:58.250162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.12.14)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2152.810413,
   "end_time": "2025-01-27T18:01:06.583913",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-27T17:25:13.773500",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
